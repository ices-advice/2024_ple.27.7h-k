ContactPerson = "claire.moore@marine.ie",
Purpose = "Advice",
StockCategory = "3.2", # rfb rule, see https://vocab.ices.dk/?ref=1526
ModelType = "None", # https://vocab.ices.dk/?ref=1524
ModelName = "None"
)
### add some more data manually
stk_info$CustomLimitName1 <- "Itrigger" ### for biomass index plot
stk_info$CustomLimitValue1 <- advice@b@Itrigger
stk_info$CustomLimitName2 <- "Fmsy proxy" ### for length-based indicator
stk_info$CustomLimitValue2 <- 1
stk_info$StockSizeDescription <- "Biomass Index"
stk_info$StockSizeUnits <- "t" ### units: https://vocab.ices.dk/?ref=155
stk_info$ConfidenceIntervalDefinition	 <- "95%"
stk_info$CatchesLandingsUnits <- "t" ### t for tonnes
stk_info$CustomSeriesUnits1 <- "ratio"
stk_info$CustomSeriesName1 <- "Length-based Fishing Pressure Proxy"
### get and format data
df_catch <- catch %>%
select(Year = year,
Landings = ICES_landings,
Discards = ICES_discards) %>%
filter(!is.na(Landings))
df_idx <- advice@r@idx %>%
select(Year = year, StockSize = index, Low_StockSize = low_stocksize  , High_StockSize = high_stocksize)
df_f <- advice@f@indicator %>%
ungroup() %>%
select(Year = year, CustomSeries1 = inverse_indicator)
df <- full_join(df_catch, df_idx) %>%
full_join(df_f)
### set up data
# https://datsu.ices.dk/web/selRep.aspx?Dataset=126  # Record: AF - Fish Data
stk_data <- stockFishdata(
Year = df$Year,
Landings = df$Landings,
Discards = df$Discards,
StockSize = df$StockSize,
Low_StockSize = df$Low_StockSize,
High_StockSize = df$High_StockSize,
CustomSeries1 = df$CustomSeries1
)
### save as XML file
xmlfile <- createSAGxml(stk_info, stk_data)
writeLines(xmlfile, paste0("report/standard_graphs/ple.27.7h-k_", ass_yr, ".xml"))
### this file can be manually uploaded at
### https://standardgraphs.ices.dk/manage/index.aspx
### Alternatively: do it all from R (see below)
### ------------------------------------------------------------------------ ###
### automatic upload of data and configuration of plots/data ####
### ------------------------------------------------------------------------ ###
### ICES standard graphs
### create token for authentication
### go to https://standardgraphs.ices.dk/manage/index.aspx
### login
### click on create token or go directly to
### https://standardgraphs.ices.dk/manage/CreateToken.aspx
### create new token, save in file
# file.edit("~/.Renviron")
### in the format
### SG_PAT=some_token_......
### save and restart R
if (isTRUE(verbose)) {
### load token
Sys.getenv("SG_PAT")
options(icesSAG.use_token = TRUE)
## check assessments keys
key <- findAssessmentKey("ple.27.7h-k", year = ass_yr)
key_last <- findAssessmentKey("ple.27.7h-k", year = ass_yr - 2) ### biennial
### last year's graphs
# plot(getSAGGraphs(key_last))
### doesn't work ... error 404
### last year's graphs
# settings_last <- getSAGSettingsForAStock(key_last)
### upload
key_new <- uploadStock(info = stk_info, fishdata = stk_data, verbose = TRUE)
### key_new <- 1881
# findAssessmentKey('ple.27.7e', ass_yr, full = TRUE)$AssessmentKey
### plots and settings not working properly...
#icesSAG:::plot.ices_standardgraph_list(getSpawningStockBiomassGraph(key_new))
### return a plot with text "is not published yet"...
# ### check upload
# windows() ### RStudio's interal plot pane causes RStudio to crash...
# plot(getSAGGraphs(key_new))
#
# ### get chart settings
# ### should be automatically copied from last year
# chart_settings <- getSAGSettingsForAStock(key_new)
#
# plot(getLandingsGraph(key_new))
#
# ### compare with last years settings
# settings_last <- getSAGSettingsForAStock(key_last)
# all.equal(chart_settings, settings_last)
# ### yes, identical (only new assessment key)
### modify chart settings
### possible options listed here:
### https://standardgraphs.ices.dk/manage/ListSettings.aspx
# ### check again
# getSAGSettingsForAStock(key_new)
# windows()
# plot(getSAGGraphs(key_new))
#
}
View(idxB)
### ------------------------------------------------------------------------ ###
### Preprocess data, write TAF data tables ####
### ------------------------------------------------------------------------ ###
## Before: boot/data/FSP7e.csv
##         boot/data/advice/advice_history.csv
##         boot/data/InterCatch_length.csv
## After:  data/idx.csv
##         data/advice_history.csv
##         data/length_data.rds
# R version 4.4.0
library(icesTAF)
taf.libPaths()
library(tidyr)
library(dplyr)
taf.bootstrap() #run to create copy of inital folder into data folder
### create folder to store data
mkdir("data")
### ------------------------------------------------------------------------ ###
### Biomass index data ####
### ------------------------------------------------------------------------ ###
### 1 biomass index: VAST index - 5 suveys combined
### - biomass in estimated metric tonnes
### load data from csv
idxB <- read.csv("boot/data/VAST_biomass.csv")
#Add in confidence intervals (2*SD)
#idxB$confid_inter <- 2*sd(idxB$index)
#Add in confidence intervals (95%)
#To calculate a confidence interval, we need the following steps (https://bookdown.org/logan_kelly/r_practice/p09.html)
#1. Calculate the mean
sample.mean <- mean(idxB$Estimate_metric_tons)
#2. Calculate the standard error of the mean
sample.n <- length(idxB$Estimate_metric_tons)
#sample.sd <-  idxB$SD_mt  #sd(idxB$Estimate_metric_tons) #we estimate metric tonnes
idxB$sample.se <- idxB$SD_mt/sqrt(sample.n)
#3.Find the t-score that corresponds to the confidence level
alpha = 0.05 #1-0.95
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)
#4. Calculate the margin of error and construct the confidence interval
idxB$margin.error <- t.score * idxB$sample.se
idxB$lower.bound <- sample.mean - idxB$margin.error
idxB$upper.bound <- sample.mean + idxB$margin.error
idxB$Low_StockSize <- idxB$index -idxB$lower.bound
library(icesTAF)
taf.libPaths()
library(tidyr)
library(dplyr)
taf.bootstrap() #run to create copy of inital folder into data folder
### create folder to store data
mkdir("data")
### load data from csv
idxB <- read.csv("boot/data/VAST_biomass.csv")
#1. Calculate the mean
sample.mean <- mean(idxB$Estimate_metric_tons)
#2. Calculate the standard error of the mean
sample.n <- length(idxB$Estimate_metric_tons)
#sample.sd <-  idxB$SD_mt  #sd(idxB$Estimate_metric_tons) #we estimate metric tonnes
idxB$sample.se <- idxB$SD_mt/sqrt(sample.n)
#3.Find the t-score that corresponds to the confidence level
alpha = 0.05 #1-0.95
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)
#4. Calculate the margin of error and construct the confidence interval
idxB$margin.error <- t.score * idxB$sample.se
idxB$lower.bound <- sample.mean - idxB$margin.error
idxB$upper.bound <- sample.mean + idxB$margin.error
head(idxB)
### ------------------------------------------------------------------------ ###
### Preprocess data, write TAF data tables ####
### ------------------------------------------------------------------------ ###
## Before: boot/data/FSP7e.csv
##         boot/data/advice/advice_history.csv
##         boot/data/InterCatch_length.csv
## After:  data/idx.csv
##         data/advice_history.csv
##         data/length_data.rds
# R version 4.4.0
library(icesTAF)
taf.libPaths()
library(tidyr)
library(dplyr)
taf.bootstrap() #run to create copy of inital folder into data folder
### create folder to store data
mkdir("data")
### ------------------------------------------------------------------------ ###
### Biomass index data ####
### ------------------------------------------------------------------------ ###
### 1 biomass index: VAST index - 5 suveys combined
### - biomass in estimated metric tonnes
### load data from csv
idxB <- read.csv("boot/data/VAST_biomass.csv")
#Add in confidence intervals (2*SD)
#idxB$confid_inter <- 2*sd(idxB$index)
#Add in confidence intervals (95%)
#To calculate a confidence interval, we need the following steps (https://bookdown.org/logan_kelly/r_practice/p09.html)
#1. Calculate the mean
sample.mean <- mean(idxB$Estimate_metric_tons)
#2. Calculate the standard error of the mean
sample.n <- length(idxB$Estimate_metric_tons)
#sample.sd <-  idxB$SD_mt  #sd(idxB$Estimate_metric_tons) #we estimate metric tonnes
idxB$sample.se <- idxB$SD_mt/sqrt(sample.n)
#3.Find the t-score that corresponds to the confidence level
alpha = 0.05 #1-0.95
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)
#4. Calculate the margin of error and construct the confidence interval
idxB$margin.error <- t.score * idxB$sample.se
idxB$lower.bound <- sample.mean - idxB$margin.error
idxB$upper.bound <- sample.mean + idxB$margin.error
idxB$Low_StockSize <- idxB$Estimate_metric_tons -idxB$lower.bound
idxB$High_StockSize  <- idxB$Estimate_metric_tons + idxB$upper.bound
## Format for cat3advice functions
idxB <- idxB %>% select(Year, index= Estimate_metric_tons, Low_StockSize, High_StockSize )
### save in data directory
write.taf(idxB, file = "data/idx.csv")
saveRDS(idxB, file = "data/idx.rds")
### ------------------------------------------------------------------------ ###
### catch and advice data ####
### ------------------------------------------------------------------------ ###
catch <- read.csv("boot/data/advice_history.csv")
names(catch)[1] <- "year"
write.taf(catch, file = "data/advice_history.csv")
saveRDS(catch, file = "data/advice_history.rds")
### ------------------------------------------------------------------------ ###
### length data ####
### ------------------------------------------------------------------------ ###
### raised data from InterCatch
### load data
lngth_full <- read.csv("boot/data/Canum_Reviewied_Years_SOP_2004-2023.csv")
### summarise data
lngth <- lngth_full %>%
### treat "BMS landing"/"Logbook Registered Discard" as discards
mutate(CatchCategory = ifelse(Catch.Cat. == "Landings",
"Landings", "Discards")) %>%
#filter(CatchCategory %in% c("Discards", "Landings")) %>%
select(year = Year, catch_category = Catch.Cat., length = Length,
numbers = Frequency) %>%
group_by(year, catch_category, length) %>%
summarise(numbers = sum(numbers)) %>%
filter(numbers > 0)
write.taf(lngth, file = "data/length_data.csv")
saveRDS(lngth, file = "data/length_data.rds")
### ------------------------------------------------------------------------ ###
### Apply rfb rule ####
### ------------------------------------------------------------------------ ###
## Before: data/idx.csv
##         data/advice_history.csv
##         data/length_data.rds
## After:  model/advice.rds
# R version 4.4.0
library(icesTAF)
taf.libPaths()
library(cat3advice)
library(dplyr)
mkdir("model")
### ------------------------------------------------------------------------ ###
### load data ####
### ------------------------------------------------------------------------ ###
### history of catch and advice
catch <- read.taf("data/advice_history.csv")
catch_A <- catch %>%
select(year, advice = ICES_advice, discards = ICES_discards,
landings = ICES_landings , catch = ICES_catch)
### biomass index
idxB <- read.taf("data/idx.csv")
### catch length data
lngth <- read.taf("data/length_data.csv")
### ------------------------------------------------------------------------ ###
### reference catch ####
### ------------------------------------------------------------------------ ###
### use last catch advice (advice given in 2022 for 2023 and 2024)
A <- A(catch_A[catch_A$year <= 2024, ], units = "tonnes",
basis = "advice", advice_metric = "catch")
### ------------------------------------------------------------------------ ###
### r - biomass index trend/ratio ####
### ------------------------------------------------------------------------ ###
### 2 over 3 ratio
r <- rfb_r(idxB, units = "Estimate_metric_tons")
### ------------------------------------------------------------------------ ###
### b - biomass safeguard ####
### ------------------------------------------------------------------------ ###
### do not redefine biomass trigger Itrigger and keep value defined in 2024
### Itrigger based on Iloss (2007)
b <- rfb_b(idxB, units = "Estimate_metric_tons", yr_ref = 2005)
### ------------------------------------------------------------------------ ###
### f - length-based indicator/fishing pressure proxy ####
### ------------------------------------------------------------------------ ###
### calculate annual length at first capture - for information only
lc_annual <- Lc(lngth, units = "mm")
### Lc was defined at WGCSE 2024 by using data from 2017:2021
### keep this definition (do not update Lc)
lc <- Lc(lngth, average = 2017:2021, units = "mm") #same as benchmark, pool to average cause variability in sample size #dont trust labels
#lc <- Lc(228, units = "mm")
### mean annual catch length above Lc
lmean <- Lmean(lngth, Lc = lc, units = "mm")
#high variability in time series so we use the mean of time series
#lmean <- mean(lmean@summary$Lmean)
### reference length LF=M - keep value calculated at WGCSE 2022
### Linf calculated by fitting von Bertalanffy model to age-length data
lref <- Lref(basis = "LF=M", Lc = lc, Linf = 467, units = "mm")
### length indicator
f <- rfb_f(Lmean = lmean, Lref = lref, units = "mm")
### ------------------------------------------------------------------------ ###
### multiplier ####
### ------------------------------------------------------------------------ ###
### generic multiplier based on life history (von Bertalanffy k)
### k value from fitting von Bertalanffy model to survey age-length data
m <- rfb_m(k = 0.18)
### ------------------------------------------------------------------------ ###
### discard rate ####
### ------------------------------------------------------------------------ ###
discard_rate <- 35
### ------------------------------------------------------------------------ ###
### apply rfb rule - combine elements ####
### ------------------------------------------------------------------------ ###
### includes consideration of stability clause
advice <- rfb(A = A, r = r, f = f, b = b, m = m,
cap = "conditional", cap_upper = 20, cap_lower = -30,
frequency = "biennial",
discard_rate = 35)
### ------------------------------------------------------------------------ ###
### save output ####
### ------------------------------------------------------------------------ ###
saveRDS(advice, file = "model/advice.rds")
saveRDS(lc_annual, file = "model/lc_annual.rds")
### ------------------------------------------------------------------------ ###
### create ICES standard graphs for advice sheet ####
### ------------------------------------------------------------------------ ###
## Before: model/advice.rds
##         model/advice_history.rds
## After:  report/standard_graphs/ple.27.7h_k_YYYY.xml
### load packages
library(icesTAF)
library(icesSAG)
library(cat3advice)
library(dplyr)
library(tidyr)
mkdir("report/standard_graphs")
if (!exists("verbose")) verbose <- FALSE
### ------------------------------------------------------------------------ ###
### load data ####
### ------------------------------------------------------------------------ ###
advice <- readRDS("model/advice.rds")
catch <- read.taf("data/advice_history.csv")
### ------------------------------------------------------------------------ ###
### create SAG objects ####
### ------------------------------------------------------------------------ ###
### assessment year
ass_yr <- 2024
### list of possible elements:
### https://datsu.ices.dk/web/selRep.aspx?Dataset=126
### allowed units:
### https://vocab.ices.dk/?ref=155
### set up stock info
stk_info <- stockInfo(
StockCode = "ple.27.7h-k",
AssessmentYear = ass_yr,
ContactPerson = "claire.moore@marine.ie",
Purpose = "Advice",
StockCategory = "3.2", # rfb rule, see https://vocab.ices.dk/?ref=1526
ModelType = "None", # https://vocab.ices.dk/?ref=1524
ModelName = "None"
)
### add some more data manually
stk_info$CustomLimitName1 <- "Itrigger" ### for biomass index plot
stk_info$CustomLimitValue1 <- advice@b@Itrigger
stk_info$CustomLimitName2 <- "Fmsy proxy" ### for length-based indicator
stk_info$CustomLimitValue2 <- 1
stk_info$StockSizeDescription <- "Biomass Index"
stk_info$StockSizeUnits <- "t" ### units: https://vocab.ices.dk/?ref=155
stk_info$ConfidenceIntervalDefinition	 <- "95%"
stk_info$CatchesLandingsUnits <- "t" ### t for tonnes
stk_info$CustomSeriesUnits1 <- "ratio"
stk_info$CustomSeriesName1 <- "Length-based Fishing Pressure Proxy"
### get and format data
df_catch <- catch %>%
select(Year = year,
Landings = ICES_landings,
Discards = ICES_discards) %>%
filter(!is.na(Landings))
df_idx <- advice@r@idx %>%
select(Year = year, StockSize = index, Low_StockSize = low_stocksize  , High_StockSize = high_stocksize)
df_f <- advice@f@indicator %>%
ungroup() %>%
select(Year = year, CustomSeries1 = inverse_indicator)
df <- full_join(df_catch, df_idx) %>%
full_join(df_f)
### set up data
# https://datsu.ices.dk/web/selRep.aspx?Dataset=126  # Record: AF - Fish Data
stk_data <- stockFishdata(
Year = df$Year,
Landings = df$Landings,
Discards = df$Discards,
StockSize = df$StockSize,
Low_StockSize = df$Low_StockSize,
High_StockSize = df$High_StockSize,
CustomSeries1 = df$CustomSeries1
)
### save as XML file
xmlfile <- createSAGxml(stk_info, stk_data)
writeLines(xmlfile, paste0("report/standard_graphs/ple.27.7h-k_", ass_yr, ".xml"))
### this file can be manually uploaded at
### https://standardgraphs.ices.dk/manage/index.aspx
### Alternatively: do it all from R (see below)
### ------------------------------------------------------------------------ ###
### automatic upload of data and configuration of plots/data ####
### ------------------------------------------------------------------------ ###
### ICES standard graphs
### create token for authentication
### go to https://standardgraphs.ices.dk/manage/index.aspx
### login
### click on create token or go directly to
### https://standardgraphs.ices.dk/manage/CreateToken.aspx
### create new token, save in file
# file.edit("~/.Renviron")
### in the format
### SG_PAT=some_token_......
### save and restart R
if (isTRUE(verbose)) {
### load token
Sys.getenv("SG_PAT")
options(icesSAG.use_token = TRUE)
## check assessments keys
key <- findAssessmentKey("ple.27.7h-k", year = ass_yr)
key_last <- findAssessmentKey("ple.27.7h-k", year = ass_yr - 2) ### biennial
### last year's graphs
# plot(getSAGGraphs(key_last))
### doesn't work ... error 404
### last year's graphs
# settings_last <- getSAGSettingsForAStock(key_last)
### upload
key_new <- uploadStock(info = stk_info, fishdata = stk_data, verbose = TRUE)
### key_new <- 1881
# findAssessmentKey('ple.27.7e', ass_yr, full = TRUE)$AssessmentKey
### plots and settings not working properly...
#icesSAG:::plot.ices_standardgraph_list(getSpawningStockBiomassGraph(key_new))
### return a plot with text "is not published yet"...
# ### check upload
# windows() ### RStudio's interal plot pane causes RStudio to crash...
# plot(getSAGGraphs(key_new))
#
# ### get chart settings
# ### should be automatically copied from last year
# chart_settings <- getSAGSettingsForAStock(key_new)
#
# plot(getLandingsGraph(key_new))
#
# ### compare with last years settings
# settings_last <- getSAGSettingsForAStock(key_last)
# all.equal(chart_settings, settings_last)
# ### yes, identical (only new assessment key)
### modify chart settings
### possible options listed here:
### https://standardgraphs.ices.dk/manage/ListSettings.aspx
# ### check again
# getSAGSettingsForAStock(key_new)
# windows()
# plot(getSAGGraphs(key_new))
#
}
### ------------------------------------------------------------------------ ###
### Preprocess data, write TAF data tables ####
### ------------------------------------------------------------------------ ###
## Before: boot/data/FSP7e.csv
##         boot/data/advice/advice_history.csv
##         boot/data/InterCatch_length.csv
## After:  data/idx.csv
##         data/advice_history.csv
##         data/length_data.rds
# R version 4.4.0
library(icesTAF)
taf.libPaths()
library(tidyr)
library(dplyr)
taf.bootstrap() #run to create copy of inital folder into data folder
### create folder to store data
mkdir("data")
### ------------------------------------------------------------------------ ###
### Biomass index data ####
### ------------------------------------------------------------------------ ###
### 1 biomass index: VAST index - 5 suveys combined
### - biomass in estimated metric tonnes
### load data from csv
idxB <- read.csv("boot/data/VAST_biomass.csv")
#Add in confidence intervals (2*SD)
#idxB$confid_inter <- 2*sd(idxB$index)
#Add in confidence intervals (95%)
#To calculate a confidence interval, we need the following steps (https://bookdown.org/logan_kelly/r_practice/p09.html)
#1. Calculate the mean
sample.mean <- mean(idxB$Estimate_metric_tons)
#2. Calculate the standard error of the mean
sample.n <- length(idxB$Estimate_metric_tons)
#sample.sd <-  idxB$SD_mt  #sd(idxB$Estimate_metric_tons) #we estimate metric tonnes
idxB$sample.se <- idxB$SD_mt/sqrt(sample.n)
#3.Find the t-score that corresponds to the confidence level
alpha = 0.05 #1-0.95
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)
#4. Calculate the margin of error and construct the confidence interval
idxB$margin.error <- t.score * idxB$sample.se
idxB$lower.bound <- sample.mean - idxB$margin.error
idxB$upper.bound <- sample.mean + idxB$margin.error
idxB$Low_StockSize <- idxB$Estimate_metric_tons -idxB$lower.bound
idxB$High_StockSize  <- idxB$Estimate_metric_tons + idxB$upper.bound
